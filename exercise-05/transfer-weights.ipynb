{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea5da4d2a4080c8c",
   "metadata": {},
   "source": [
    "Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "id": "27da7af4ce4432d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:00:53.345498Z",
     "start_time": "2025-02-19T02:00:53.336988Z"
    }
   },
   "source": [
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "c798932180124de2",
   "metadata": {},
   "source": "Define the GPT model architecture"
  },
  {
   "cell_type": "code",
   "id": "1d809ed738cc0c28",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:00:54.735554Z",
     "start_time": "2025-02-19T02:00:54.732025Z"
    }
   },
   "source": [
    "class CustomGPTModel(GPT2LMHeadModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "id": "ac7dfa2dcb22e21f",
   "metadata": {},
   "source": "Function that generates text using the trained model."
  },
  {
   "cell_type": "code",
   "id": "deebd924bfeafc22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:00:58.020619Z",
     "start_time": "2025-02-19T02:00:58.011485Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "- max_length=50 Limits text length to avoid excessively long responses.\n",
    "- temperature=1.0 Controls randomness; 1.0 keeps a balance between predictability and creativity.\n",
    "- top_k=50 Limits next-word choices to the top 50 most likely words, reducing nonsensical outputs.\n",
    "- top_p=0.95 Ensures only the most probable words (within 95% of probability mass) are selected.\n",
    "\"\"\"\n",
    "def generate_text(model, tokenizer, prompt, max_length=50, temperature=1.0, top_k=50, top_p=0.95):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids,\n",
    "            max_length=max_length,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p,\n",
    "            do_sample=True\n",
    "        )\n",
    "    return tokenizer.decode(output[0], skip_special_tokens=True)"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "id": "c52a523946562fe4",
   "metadata": {},
   "source": "Load the pre-trained GPT-2 model and tokenizer from Hugging Face"
  },
  {
   "cell_type": "code",
   "id": "8e310caaa4b95400",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:01:02.138316Z",
     "start_time": "2025-02-19T02:01:02.135835Z"
    }
   },
   "source": "pretrained_model_name = 'gpt2'",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "id": "f6b15d4fbd668db1",
   "metadata": {},
   "source": "Load the tokenizer"
  },
  {
   "cell_type": "code",
   "id": "d7762af79136de65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:01:03.889819Z",
     "start_time": "2025-02-19T02:01:03.634903Z"
    }
   },
   "source": "tokenizer = GPT2Tokenizer.from_pretrained(pretrained_model_name)",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "id": "e4fa38d002cbb071",
   "metadata": {},
   "source": "Load the model"
  },
  {
   "cell_type": "code",
   "id": "17a519b75a89f4de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:01:07.917758Z",
     "start_time": "2025-02-19T02:01:06.466573Z"
    }
   },
   "source": "pretrained_model = GPT2LMHeadModel.from_pretrained(pretrained_model_name)",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "id": "86e6dd2d3588c4fe",
   "metadata": {},
   "source": "Initialize the custom model with the same configuration as the pre-trained model"
  },
  {
   "cell_type": "code",
   "id": "6529862cfb1d892e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:01:12.123009Z",
     "start_time": "2025-02-19T02:01:08.218194Z"
    }
   },
   "source": [
    "config = pretrained_model.config\n",
    "custom_model = CustomGPTModel(config)"
   ],
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Transfer weights from the pre-trained model to the custom model",
   "id": "d50f25b64a79afb9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:02:49.806273Z",
     "start_time": "2025-02-19T02:02:49.516413Z"
    }
   },
   "cell_type": "code",
   "source": "custom_model.load_state_dict(pretrained_model.state_dict())",
   "id": "edbe054fda0ac773",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Model is in evaluation mode",
   "id": "e2092674a14e3d60"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:02:51.023170Z",
     "start_time": "2025-02-19T02:02:51.013141Z"
    }
   },
   "cell_type": "code",
   "source": "custom_model.eval()",
   "id": "3549d39d3e6f279b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomGPTModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50257, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0-11): 12 x GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D(nf=2304, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=768)\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D(nf=3072, nx=768)\n",
       "          (c_proj): Conv1D(nf=768, nx=3072)\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Generate text",
   "id": "eade961bf33e9be1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-19T02:03:14.183904Z",
     "start_time": "2025-02-19T02:03:12.481945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "prompt = \"The DeepSeek model is \"\n",
    "generated_text = generate_text(custom_model, tokenizer, prompt)\n",
    "print(generated_text)\n"
   ],
   "id": "face032d8272cc29",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The DeepSeek model is Â a low-cost, high-value, highly customizable data warehouse system that enables you to take advantage of all of the information stored on a website like Amazon's site to save time and reduce costs.\n",
      "The\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
